---
title: "How will the stock market react to the PCA: Envidence From Yahoo Finance Stock Market"
author:
- familyname: Jin
  othernames: Kaiwen
  address: Monash University 
  email: kjin7@student.monash.edu
  correspondingauthor: true
  qualifications: 26686953
- familyname: Zhang
  othernames: Zhiruo
  address: Monash University
  email: zzha0001@student.monash.edu
  correspondingauthor: true
  qualifications: 28009487
- familyname: Luo
  othernames: Jinhao
  address: Monash University
  email: jluo0015@student.monash.edu
  correspondingauthor: true
  qualifications: 29012449
department: Department of\newline Econometrics &\newline Business Statistics
organization: ETF5500 Assignment2
bibliography: references.bib
biblio-style: authoryear-comp
linestretch: 1.5
output:
  MonashEBSTemplates::report:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
    toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=FALSE, messages=FALSE, warning=FALSE)
# Make sure you have the latest versions of rmarkdown and bookdown installed
library(dplyr)
library(ggplot2)
library(tidyverse)
library(mclust)
library(visdat)
library(gridExtra)
library(kableExtra)
library(tibble)
```

\clearpage

# Introduction

In financial market, the value of stocks would be investigated by many different variables. However, the large number of variables of each stock might make readers hard to make the comparison. Therefore, this report would apply linear combination (LC) to combine all the variables into a index and utilise principal component analysis (PCA) to help with evaluating stocks. Principal components (PCs) are the indexes of linear combination which explain the variance of the original variables, and the variance could help with differentiating the performing of each observations. PCA plays an important role in evaluating the potential values and risks of each stock, which   utilises the small number of the PCs to explain the general variation in the original data.

In addition, this report will also consider the PCA method whether is a good measurement in the stock pricing and risk measuring. By investigating the measurement of stock value and stock risk to further find our the potential limitation that PCA might face. 

Furthermore, the performance of PCA will also be compared with another method which is Clustering Analysis to check the accuracy of our result. At last, some useful suggestions for the stocks choosing will be concluded, as well as concluding the biases generated from the limitations in analysis.

-Modified:
In financial market, the value of stocks would be investigated by many different variables. However, the large number of variables of each stock might make investors hard to make their decision. Therefore, this report would apply linear combination (LC) to combine all the variables into a index and utilise principal component analysis (PCA) to evaluate the performance of stocks. 

In addition, this report will also consider the accuracy of PCA and will discuss about the potential limitation of PCA in the stock performance evaluation. Based on the result, the comparative analysis with Clustering Approach will also be provided. 

At last, some useful suggestions for the stocks choosing will be concluded, as well as concluding the biases generated from the limitations in analysis.

The appendix will contain some notes which would be helpful in understanding our reports.

# Data Description

```{r data, message=FALSE}
stocks_ori <- read_csv("stocks.csv")
#nrow(stocks)
#head(stocks)
stocks_ori <- stocks_ori%>%
  rename(intra_day=`Market cap (intra-day)`,
         ent_value=`Enterprise value`,
         trail_pe=`Trailing P/E`,
         for_pe=`Forward P/E`,
         peg=`PEG ratio (5-yr expected)`,
         ttm=`Price/sales (ttm)`,
         mrq=`Price/book (mrq)`,
         rev=`Enterprise value/revenue`,
         ebitda=`Enterprise value/EBITDA`,
         tot_risk = `Total ESG risk score`,
         envir_risk = `Environmental Risk Score`,
         social_risk = `Social Risk Score`,
         gover_risk = `Governance Risk Score`)
```

## Description
The data which used in this report was sourced from [Yahoo Finance](https://au.finance.yahoo.com/). Table \@ref(tab:variables-table) shows the information of the variables from the original data, as well as the abbreviation of the variables. The dataset contains 18 variables of 147 stocks from five major financial indices. Those 18 variables could be further classified into 3 categories. The first categories captures the 5 variables provides the basic background of those stocks which are **Name**, **Symbol**, **Market**, **Sector**, **Industry**. The second and third categories provide some measurement of the value and risk which are related to the stocks. The further description of those variables are shown in the table below: 

```{r variables-table, message=FALSE}
tribble(~Names, ~Abbreviation, ~Description,
        "Market capitalization", "intra_day", "How much a company is worth as determined by the stock market", 
        "Enterprise value", "ent_value", "A measure of a company's total value", 
        "Trailing P/E", "trail_pe",  "Price to Earning Ratio based on the earnings per share over the previous 12 months",
        "Forward P/E ratio", "for_pe",  "Estimate further earnings per share in the next 12 months", 
        "PEG ratio", "peg", "Enhances the P/E ratio by adding the expected earnings growth into calculation", 
        "P/S ratio", "ttm", "Price to Sales ratio, a valuation ratio by comparing a companyâ€™s stock price to its revenue", 
        "P/B ratio",  "mrq", "Price to Book ratio is a measurement of the market's valuation of a company relative to its book value",
        "Enterprise value-to-revenue",  "rev", "Also refers as the EV/R, it measures the value of a stock that compares a company's enterprise value to its revenue", 
        "EV/EBITDA", "ebitda", "Enterprise value to earnings before interest, taxed, depreciation and amortization ratio compares the value of a company, debt included to the company's cash earnings less non-cash expenses", 
        "Total ESG risk score", "tot_risk", "The overall rating scores based on the Morningstar Sustainability Rating systems", 
        "Environmental Risk Score", "envir_risk", "Evaluation scores of the portfolios performance when they meet the environmental challenges", 
        "Social Risk Score", "social_risk", "Evaluation scores of the portfolios performance when they meet the social challenges", 
        "Governance Risk Score", "gover_risk","Evaluation scores of the portfolios performance when they meet the governance challenges") %>% 
  kable(caption = "Information of variables of the original data") %>% 
  kable_styling(bootstrap_options = c("bordered", "striped", "hover")) %>%
  column_spec(3, width = "150px") 
```

## Limitation

In this part we will briefly introduce a couple of limitations in our dataset and those limitation will also be discussed in the following section. 

- This dataset contains a lot of missing value which would cause some bias in our final result
- This dataset does not contain enough observations. The insufficient sample space will make our final result become unreliable. In addition, if we further filter out the missing values, the sample size of the data would be even smaller. And the relatively small sample would not be representative enough to clarify the overall condition. 
- There is some inconsistency between total ESG risk score and sum of individual ESG risk score. This inconsistency would directly increase the error in our final output. 

Those limitations would be further discussed in following sections. At last, the biases in analysis which generate from the limitations would be concluded.

# Analysis 

## Preliminary Analysis 

Based on the original dataset, we will firstly tidy it by removing the missing variables and further figure out other features. Figure \@ref(fig:vis-data) shows the general data structure and it could be classified into three types which are character, numeric and missing value.

```{r vis-data, fig.cap="The data structure of original data"}
vis_dat(stocks_ori)
```

Table \@ref(tab:summary-table) indicates that the initial 147 observations have up to 102 missing value and also some potential outliers.

```{r sum-tab, eval = FALSE}
sum_tab<-stocks_ori%>%
   select(-Name,-Symbol,-Market,-Sector,-Industry)%>%
   summary(stocks_ori)
```

```{r summary-table}
tribble(~Names, ~Min, ~Median, ~Mean, ~Max, ~`NA`,
        "intra_day","-2","63","95065","5110000","NA",
        "ent_value" ,"-264","70","85683","5130000","NA",
        "trail_pe" ,"0.48","20.11","43.62","1479.29", "18",
        "for_pe","3.59","19.92","43.04","1044.81", "80",
        "peg" ,"-62.380","2.405","15.223","713.670","81",
        "ttm" ,"0.9","2.8","9.941","548.150","17",
        "mrq" ,"0.1","5.4","174.16","11765.96","10",
        "rev" ,"-27.720","2.875","9.827","5411.160","17",
        "ebitda" ,"-465.460","13.765","19.461","1117.510","23",
        "tot_risk","11","23","25.39","75","13",
        "envir_risk","0","4","6.731","62", "13",
        "social_risk","3","10","11.4","88","13",
        "gover_risk","3","8" ,"9.343","80","13") %>%
  kable(caption = "Summary table of original data") %>%
  kable_styling(bootstrap_options = c("bordered", "striped", "hover"))
```

Most of the variables have the really small median and mean, but a extremely high maximum value. Those extreme value would definitely dominate our Principle Component Analysis and those outliers are shown below:

- outliers in `intra_day` and `ent_value`: MSFT & AAPL
- outliers in `trail_pe`: TSLA
- outliers in `for_pe`: ILMN & TSLA
- outliers in `peg`: DIS, VZ, KO, MMM, CVX, PCAR, CAT, XOM
- outliers in `ttm`: ILMN, V
- outliers in `mrq`: TSLA
- outliers in `rev`: ILMN, V
- outliers in `ebitda`: INTU, ILMN, TSLA, NKE

New dataset **stocks** will be generated by removing the missing value. 

```{r stocks}
stocks <- na.omit(stocks_ori)
```

## Principle Component Analysis

### Value Analysis 

Value analysis will be conducted by removing the outliers. It is necessary to filter out high influential outliers and we will standardised our data as well since it is based on different unit. Biplot and interpretation will also be provided. 

```{r value}
# filter out the outliers
issuer<-stocks%>%
  select(Symbol,intra_day,ent_value,trail_pe,for_pe,peg,ttm,mrq,rev,ebitda)
df <- issuer[!(issuer$Symbol %in% c("MSFT", "AAPL", "TSLA", "ILMN", "DIS", "VZ", "KO", "MMM", "CVX", "PCAR", "CAT", "XOM", "V", "INTU", "NKE")),]
#view(df)
```

```{r pca-value}
pca_value<-df%>%
  select_if(is.numeric)%>%
  prcomp(scale.=TRUE)
rownames(pca_value$x)<-pull(df,Symbol)
```

```{r pca-cor,fig.cap="Correlation Biplot of Stock Value"}
cor_va<-biplot(pca_value,scale=0,cex=0.8)
```

Referring to the correlation biplot Figure \@ref(fig:pca-cor) we could notice that the the PC1 is positive correlated with the measurement of the company value indication which are **intra_day** and **ent_value**. The PC2 is positive correlated with the stock earning ratio (ebitda and trail_pe) which means that the increasing in the measurement of the stock earning ratio will increase the PC2 slightly. The rest of the ratio are neither positive correlated with  PC1 nor PC2, but we could notice that the other variables which are related to the price based evaluation of the stock are pretty close to the PC2. The **peg** ratio could not be well explained by both PC1 and PV2. 

Meanwhile, this plot also highlights that the two measurement of the company value have a really strong association with each other and do not have any association with other variables which related to the stock price and earning evaluation. Therefore, we could say that the market value of a company may not influence on their stock price and earning per share. However, the relationship between those stock price and earning measurement are quite strong. 

```{r bi-dis,fig.cap="Distance Biplot of Stock Value"}
dis_va<-biplot(pca_value,xlim=c(-0.6,0.3),cex=0.8)
``` 


Distance biplot \@ref(fig:bi-dis) indicates that **Johnson & Johnson (JNJ)** and **Walmart (WMT)** have a high value in PC1, and **Activision Blizzard (ATVI)**, **Texas Instruments Incorporated (TXN)**, **Maxim Integrated Products (MXIM)** are higher in PC2. 

Meanwhile, we notice that the **Verisk analytics (VRSK)** the potential outlier for the PC1, and **JNJ** and **WMT** the potential outlier for PC2. We could explain the reason by identify the characteristic of these firm. **VRSK** is a data analytics and risk assessment firm. They mainly provide the consulting service instead of the selling goods. Therefore, being a financial service sector, they will not have a large firm size, but the stock value and EPS will be higher.  **JNJ** and **WMT** perform in the opposite way because they mainly generate profit by selling goods. The continuously increasing market share will keep their market profit in a high level.
 

```{r lim-1}
summary(pca_value)$importance %>%  
  round(4) %>% 
  kable(caption = "Summary table of PCA for value analysis of stocks") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped"))
```

```{r lim-2, fig.cap="Screeplot of PCs in PCA for value analysis of stocks"}
screeplot(pca_value, type = "lines")
```

The limitation for the value analysis also exists. 
-	After we filter out the outliers, the number of variables we put into use is 30 out of 147 and only 70.42% of the overall variation could be explained by the first two principle (Table \@ref(tab:lim-1)). The really small space size is not representative and also would not accurate enough to explain the whole stock market condition. 
-	There is some contradictory in PC selection in Screeplot (Figure \@ref(fig:lim-2)) and biplot. 
Therefore, we need to consider alternative approach to make sure of the accuracy of our suggestion.  

```{r, eval=FALSE}
stocks %>% filter(Industry == "Technology")
```

### Risk Analysis

In this part, we will discuss about the potential risk of each stock based on the ESG risk score. We will compare the total risk score with the sum of the ESG scores to make sure the consistency of our data. Filtering out the inconsistent value would improve the accuracy of our result. 

Meanwhile, this report would also need to consider which PCs should be used. Table \@ref(tab:pca-risk-summary) shows the summary statistics of components. It is clear that PC1 and PC2 have explained almost 86% of the total variation of 4 variables. Besides, figure \@ref(fig:pca-risk-screeplot) also suggests that principal component of one and two should be selected because they all with a variance greater than 1 according to the Kaiser's Rule.

```{r risk-df}
# filter out the outliers
risk <- subset(stocks[(stocks$Symbol %in% df$Symbol),], select = c("Symbol", "tot_risk", "envir_risk", "social_risk", "gover_risk"))
#view(risk)
```

```{r first-check}
d <- apply(cbind(risk$envir_risk, risk$social_risk, risk$gover_risk), 1, sum)
#all(risk$tot_risk == d)
```

```{r risk-data}
# checking if total esg risk score = environmrnt + social + government 
risk_tesg <- risk[risk$tot_risk == d,]
d2 <- apply(cbind(risk_tesg$envir_risk, risk_tesg$social_risk, risk_tesg$gover_risk), 1, sum)
#all(risk_tesg$tot_risk == d2)
#head(risk_tesg)
#nrow(risk_tesg)
```

```{r principal-component-analysis}
pca_risk <- risk_tesg %>% select_if(is.numeric) %>% prcomp(scale. = TRUE)
```

```{r pca-risk-summary}
summary(pca_risk)$importance %>%  
  round(4) %>%
  kable(caption = "Summary table of PCA for risks analysis of stocks") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped"))
```

```{r pca-risk-screeplot, fig.cap="Screeplot of PCs in PCA for risk analysis of stocks"}
screeplot(pca_risk, type = "lines")
```

Figure \@ref(fig:pca-risk-distance) shows the distance among each stock in the dataset, and implies the similarity between stocks. The stocks of **VRSK** and **UnitedHealth Group Incorporated (UNH)** may be exactly same because they seem perfectly superimpose. Besides, **Allianz SE (ALV.DE)** and **Dollar Tree, Inc. (DLTR)**, as well as **Cerner Corporation (CERN)** and **Fiserv, Inc. (FISV)** might be similar, because they are close to each other. While the stocks like **VRSK** and **Microchip Technology Incorporated (MCHP)**, or **CDW Corporation (CDW)** and **Pfizer Inc. (PFE)** might be different because they are far away from each other. In order to further analysing the correlation between each stock, a correlation biplot is required.

```{r pca-risk-distance, fig.height=5, fig.cap= "Distance biplot of PCA of stocks' risk"}
rownames(pca_risk$x) <- pull(risk_tesg, Symbol)
biplot(pca_risk, xlim=c(-0.5, 0.5), ylim = c(-0.6, 0.3),  cex = 0.8)
```

Figure \@ref(fig:pca-risk-correlation) explains the correlation between different risk scores, as well as the correlation between different stocks. Or even allow readers to compare stocks to different types of risk. **VRSK**, **UNH**, **CERN**, and **FISV** with the high values of social risk score, which indicate that these four stocks might perform better than the others when facing the social challenges. While, those stocks might not be good at facing the challenges from environmental risks because the angle between social risk score and  environmental risk socre is close to 180 degree, which imply a highly negative correlation approximately. In contrast, **Covestro AG (1COV.DE)** and **MCHP** have the strongest abilities to face the environmental challenges. Meanwhile, **MCHP** also has the highest score of governance risk, which indicates a good performance when meeting the governance challenges. Besides, **PFE**, **Bayerische Motoren Werke AG (BMW.DE)**, and **Merck & Co., Inc. (MRK)** also perform well in governance challenges. While because of the projected positions of these three stocks along the axis of governance risk score are gradually decreasing, the approximate actual values of stocks performance might gradually decline.

In general, based on the total ESG risk score, **MCHP** and **BMW.DE** are the stock with the best overall performance compared with other stocks, which indicate that they might be hard to be influences by challenges, and have strong resilience when meeting risks. Therefore, there might not be significant fluctuations of them when facing challenges, and could be stable. In contrast, the stock of **CDW** has a weak overall performance when facing challenges because the approximation actual value in the axis of total risk score is very low. It indicates that the risks might impact on **CDW** easily, and **CDW** might experience a significant fluctuation when facing risks.  

```{r pca-risk-correlation, fig.height=5, fig.cap="Correlation biplot of PCA of stocks' risk"}
biplot(pca_risk, scale = 0, xlim = c(-4, 4), cex = 0.8)
```

```{r, eval=FALSE}
summary(pca_risk)
pca_risk$x 
pca_risk$rotation
```

```{r pca-risk-observations, eval=FALSE}
pca_risk$x %>%
  kable(caption = "") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped"))
```

```{r pca-risk-weights, eval=FALSE}
pca_risk$rotation %>%
  kable(caption = "") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped"))
```

## Cluster Analysis

Using the hierarchical clustering analysis with agglomerative method, it is a bottom-up approach. We first select the data set that is consistent with the value data by equivalent stocks symbol. After standardised the data for the numeric variables, we use the Euclidian distance to find the distance between all pairs of observations. We employ the Ward's methodology to sort the clusters. And the resulting of clusters are shown in the dendogram, which is a tree-like diagram that displays the sequences of merges or splits. Based on the Figure \@ref(fig:ward), the two and four clusters solutions are not stable. Hence, the three cluster solution is stable which is shown in \@ref(fig:ward-3).

```{r dat-cluster}
dat <- stocks[(stocks$Symbol %in% df$Symbol),]
d <- dat %>% select_if(is.numeric) %>% scale %>% dist 
```

```{r ward, fig.cap="Choosing clusters"}
hc_w <- hclust(d, method = "ward.D2")
hc_w$labels <- dat$Symbol
par(mfrow = c(1,3))
plot(hc_w, cex = 0.5, xlab= "Stocks", ylab="Distance")
rect.hclust(hc_w, k = 2)
plot(hc_w, cex = 0.5, xlab= "Stocks", ylab="Distance")
rect.hclust(hc_w, k = 3)
plot(hc_w, cex = 0.5, xlab= "Stocks", ylab="Distance")
rect.hclust(hc_w, k = 4)
```

```{r ward-3, fig.cap="Dendogram using Ward methodology and taking Euclidian distances"}
plot(hc_w, cex = 0.5, xlab= "Stocks", ylab="Distance")
rect.hclust(hc_w, k = 3)
```

From the dendogram, there are three different clusters. Table \@ref(tab:memb-w) shows the first cluster of stocks, table \@ref(tab:memb-two) shows the second cluster of stocks, and table \@ref(tab:memb-three) shows the third cluster of stocks.

```{r memb-w}
memb_three_w <- cutree(hc_w, k = 3)
memb_one <- dat[dat$Symbol %in% rownames(as.data.frame(memb_three_w) %>% filter(memb_three_w == 2)),]$Name

memb_one %>% 
  kable(col.names = c("stock"), caption = "The stocks of the first cluster") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped")) 
  
```

```{r memb-two}
memb_two <- dat[dat$Symbol %in%  rownames(as.data.frame(memb_three_w) %>% filter(memb_three_w == 3)),]$Name
memb_two %>%
  kable(col.names = c("stock"), caption = "The stocks of the second cluster") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped")) 
```


```{r memb-three}
memb_three <- dat[dat$Symbol %in%  rownames(as.data.frame(memb_three_w) %>% filter(memb_three_w == 1)),]$Name
memb_three %>%
  kable(col.names = c("stock"), caption = "The stocks of the third cluster") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped")) 
```

# Conclusions 

According to our general evaluation of the Yahoo Finance market, we could say that **JNJ** and **WMT** perform better in company evaluation while **ATVI**, **TXN**, **MXIM** are better in price and earning.  **VRSK**, **JNJ** and **WMT** could be considered as the special cases since they outperform in their own area. What ESG risk analysis provides us is that **MCHP** and **BMW.DE** have a great performance in overall anti-risk, some other companies are perform better in a specific risk score. For instance, **UNH**, **CERN**, and **FISV** perform well in anti-social risk, but they are not resilient enough when meeting the challenges from environmental risk compared with **1COV.DE** and **MCHP**. And our investment suggestions are listed below:

- Fully consider the characteristics of the firm and consider the factors which might dominate in the stock value. 
- Both internal and external risks would on the value of stocks and will generate the fluctuation of prices in the stock market as well. 
- Investors need to make the investment decision based on their risk tolerance and well balance differences in the risk-control of each companies. 
- Companies need to improve the ability of self-resilience and anti-risks so than enhance the performance when facing different types of risks.


# Appendix

## Ends with Emphasis 

At the end of our report, it is necessary to emphasis that due to the small sample space and the incomplete eigenvalue selection, our result might not be representative and the biplot could not fully state the overall situation. Even though, in our case, the biplot is suitable for risks analysis. We still could not deny fact that in general the small sample size would lead to the bias in output. Therefore, our report use the cluster analysis as alternative approach The agglomerative method indicates that stable solution is three cluster. And here we would show complete linkage method (Figure \@ref(fig:complete)), average linkage (Figure \@ref(fig:average)) and centroid method (Figure \@ref(fig:centroid)). In order to check the robustness, we compute the adjusted rand index using `adjustedRandIndex` function. Table \@ref(tab:adjusted-index) indicates that the complete linkage method has a relatively high level of agreement with the Ward's method. 

```{r complete, fig.cap="Cluster dendrogram of complete linkage method"}
hc_c <- hclust(d, method = "complete")
hc_c$labels <- dat$Symbol
plot(hc_c, cex = 0.5)
rect.hclust(hc_c, k = 3)
```

```{r memb-complete}
memb_three_c <- cutree(hc_c, k = 3) 
```

```{r average, fig.cap="Cluster dendrogram of average linkage method"}
hc_al <- hclust(d, method = "average")
hc_al$labels <- dat$Symbol
plot(hc_al, cex = 0.5)
rect.hclust(hc_al, k = 3)
```

```{r memb_al}
memb_three_al <- cutree(hc_al, k = 3)
```

```{r centroid, fig.cap="Cluster dendrogram of centroid method"}
hc_cm <- hclust(d, method = "centroid")
hc_cm$labels <- dat$Symbol
plot(hc_cm, cex = 0.5)
rect.hclust(hc_cm, k = 3)
```

```{r memb_cm}
memb_three_cm <- cutree(hc_cm, k = 3)
```

```{r adjusted-index}
c <- adjustedRandIndex(memb_three_w, memb_three_c)
al <- adjustedRandIndex(memb_three_w, memb_three_al)
cm <- adjustedRandIndex(memb_three_w, memb_three_cm)


al_method <- rbind(c, al, cm) 
rownames(al_method) <- c("complete linkage method", "average linkage method", "centroid method")
al_method %>% 
  kable(col.names = c("adjusted rand index"), 
        caption = "The adjusted rand index of the three clustering methods") %>%
  kable_styling(bootstrap_options = c("bordered", "hover", "striped")) 
```

## Acknowledgement

The data could be downloaded from [Yahoo Finance](https://au.finance.yahoo.com/). Meanwhile, the report uses the template called **Monash Consulting Report** which could use by downloading the package called [MonashEBSTemplates](https://github.com/robjhyndman/MonashEBSTemplates). In addition, the programming language used to analyse the stocks is R (4.0.2) [@R].

Following packages has been included in our Rmd file:

- package dplyr (1.0.1) [@dplyr],
- package ggplot2 (3.3.2) [@ggplot2],
- package tidyverse (1.3.0) [@tidyverse],
- package mclust (5.4.6) [@mclust],
- package visdat (0.5.3) [@visdat],
- package gridExtra (2.3) [@gridExtra],
- package kableExtra (1.1.0) [@kableExtra],
- package tibble (3.0.3) [@tibble].

\clearpage

## References
